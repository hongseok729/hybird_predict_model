{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNF2OgbEdkxpU46WP/aqb8r"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["!pip install optuna\n","!pip install -U xgboost\n","!pip install optuna-integration[xgboost]"],"metadata":{"id":"U2JmGIKwvDME"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lExoMsoGu-0x"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import os\n","import joblib\n","import optuna\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import OrdinalEncoder, StandardScaler\n","from sklearn.metrics import mean_squared_error\n","from xgboost import XGBRegressor\n","from sklearn.cluster import KMeans\n","from google.colab import drive\n","\n","# 드라이브 마운트\n","drive.mount('/content/drive')\n","\n","# 경로 설정\n","file_path = ''\n","model_dir = ''\n","os.makedirs(model_dir, exist_ok=True)\n","\n","# 데이터 로드\n","df = pd.read_csv(file_path)\n","\n","# Group 매핑\n","group_map = {\n","    \"식품\": \"Group_A\", \"유아동\": \"Group_A\", \"여행/문화\": \"Group_A\",\n","    \"자동차\": \"Group_B\", \"서비스/렌탈\": \"Group_C\", \"컴퓨터/IT\": \"Group_D\",\n","    \"건강\": \"Group_E\", \"가전/디지털\": \"Group_F\", \"가구/인테리어\": \"Group_F\",\n","    \"생활/주방\": \"Group_G\", \"기타\": \"Group_G\", \"의류/패션\": \"Group_H\",\n","    \"화장품/뷰티\": \"Group_I\", \"스포츠/레저\": \"Group_J\"\n","}\n","df['Group'] = df['통합카테고리1'].map(group_map).fillna('Group_G')\n","\n","# 결측치 처리\n","df = df.dropna(subset=['Group', '시청자수'])\n","df['강수량(mm)'] = df['강수량(mm)'].fillna(df['강수량(mm)'].mean())\n","\n","# 증강 함수 정의\n","def augment_group(df_group, n_samples=300):\n","    df_group = df_group.copy()\n","    features = df_group.select_dtypes(include=['int', 'float']).drop(columns=['시청자수'], errors='ignore')\n","    features = features.fillna(features.mean())\n","    scaler = StandardScaler()\n","    scaled = scaler.fit_transform(features)\n","    kmeans = KMeans(n_clusters=3, random_state=42)\n","    df_group['cluster'] = kmeans.fit_predict(scaled)\n","\n","    rows = []\n","    for c in df_group['cluster'].unique():\n","        base = df_group[df_group['cluster'] == c]\n","        for _ in range(n_samples):\n","            noise = np.random.normal(0, 0.05, size=features.shape[1])\n","            row = base.sample(1).copy()\n","            row[features.columns] += noise\n","            row['시청자수'] = base['시청자수'].mean()\n","            rows.append(row.squeeze())\n","    return pd.DataFrame(rows)\n","\n","# 증강 적용\n","augment_targets = ['Group_B', 'Group_D', 'Group_C', 'Group_J']\n","df_aug = df.copy()\n","for g in augment_targets:\n","    aug = augment_group(df[df['Group'] == g])\n","    df_aug = pd.concat([df_aug, aug], axis=0)\n","df_aug.reset_index(drop=True, inplace=True)\n","\n","# 인코딩\n","obj_cols = df_aug.select_dtypes(include='object').columns.tolist()\n","encoder = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\n","df_aug[obj_cols] = encoder.fit_transform(df_aug[obj_cols])\n","joblib.dump(encoder, f\"{model_dir}/encoder_total_model.pkl\")\n","\n","# feature 리스트 추출 (시간 관련 컬럼 제외)\n","exclude_cols = ['시청자수', '방송일자', '방송시작시간', '방송종료시간']\n","features = [c for c in df_aug.columns if c not in exclude_cols]\n","with open(f\"{model_dir}/feature_list.txt\", \"w\") as f:\n","    for col in features:\n","        f.write(col + \"\\n\")\n","\n","# 그룹별 모델 학습\n","for group_name in sorted(df_aug['Group'].unique()):\n","    df_g = df_aug[df_aug['Group'] == group_name].copy()\n","    X, y = df_g[features], df_g['시청자수']\n","    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","    def objective(trial):\n","        params = {\n","            'n_estimators': trial.suggest_int('n_estimators', 200, 600),\n","            'max_depth': trial.suggest_int('max_depth', 3, 8),\n","            'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.2),\n","            'subsample': trial.suggest_float('subsample', 0.7, 1.0),\n","            'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0),\n","            'random_state': 42, 'n_jobs': -1\n","        }\n","        model = XGBRegressor(**params)\n","        model.fit(X_train, y_train, eval_set=[(X_val, y_val)], verbose=False)\n","        preds = model.predict(X_val)\n","        return np.sqrt(mean_squared_error(y_val, preds))\n","\n","    print(f\"[INFO] {group_name} 모델 튜닝 시작...\")\n","    study = optuna.create_study(direction='minimize')\n","    study.optimize(objective, n_trials=30)\n","\n","    final_model = XGBRegressor(**study.best_params)\n","    final_model.fit(X_train, y_train)\n","    joblib.dump(final_model, f\"{model_dir}/model_{group_name}.pkl\")\n","    print(f\" {group_name} 모델 저장 완료!\")\n","\n","# 전체 모델 학습\n","X_all, y_all = df_aug[features], df_aug['시청자수']\n","X_tr, X_vl, y_tr, y_vl = train_test_split(X_all, y_all, test_size=0.2, random_state=42)\n","\n","def objective_total(trial):\n","    model = XGBRegressor(\n","        n_estimators=trial.suggest_int('n_estimators', 100, 500),\n","        max_depth=trial.suggest_int('max_depth', 3, 10),\n","        learning_rate=trial.suggest_float('learning_rate', 0.01, 0.3),\n","        subsample=trial.suggest_float('subsample', 0.6, 1.0),\n","        colsample_bytree=trial.suggest_float('colsample_bytree', 0.6, 1.0),\n","        random_state=42, n_jobs=-1\n","    )\n","    model.fit(X_tr, y_tr)\n","    preds = model.predict(X_vl)\n","    return np.sqrt(mean_squared_error(y_vl, preds))\n","\n","print(\"모델 튜닝 시작\")\n","study_total = optuna.create_study(direction='minimize')\n","study_total.optimize(objective_total, n_trials=30)\n","\n","final_model_total = XGBRegressor(**study_total.best_params)\n","final_model_total.fit(X_tr, y_tr)\n","joblib.dump(final_model_total, f\"{model_dir}/model_total.pkl\")\n","\n","print(\"\\n 전체 학습 완료\")\n"]}]}